{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to run CorrCal with dish scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import h5py,time, matplotlib.pyplot as plt\n",
    "from scipy.optimize import fmin_cg, minimize\n",
    "from drift.core import manager\n",
    "import corrcal\n",
    "import sys\n",
    "sys.path.insert(0,'/home/zahra/PIPELINE')\n",
    "from hirax_transfer import core\n",
    "import scipy as sp\n",
    "from cora.util import hputil\n",
    "from astropy.stats import gaussian_fwhm_to_sigma\n",
    "from hirax_transfer.beams import separations\n",
    "import healpy as hp\n",
    "from cora.core import skysim\n",
    "from cora.foreground import gaussianfg, galaxy\n",
    "from cora.util import coord\n",
    "from drift.core import visibility\n",
    "sys.path.insert(0,'/home/zahra/hirax_tools/')\n",
    "from hirax_tools import array_config\n",
    "from log_red_cal_new import Visibilities_grid, Bls_counts, colour_scatterplot, Scatterplot, index_find\n",
    "from cora.foreground import poisson as ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prod params file used to generate x and y antenna positions, assuming single feed for each antenna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product directory: /home/zahra/PIPELINE/8by8_no_sims/bt_matrices\n"
     ]
    }
   ],
   "source": [
    "m = manager.ProductManager.from_config('/home/zahra/PIPELINE/8by8_no_sims/prod_params_custom.yaml') \n",
    "\n",
    "t = m.telescope\n",
    "Nfeeds,_= t.feedpositions.shape\n",
    "Ndish = np.int(Nfeeds/2)\n",
    "Nbls = np.int(Ndish*(Ndish-1)/2)\n",
    "\n",
    "x = t.feedpositions[:,0][:Ndish] \n",
    "y = t.feedpositions[:,1][:Ndish]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Introduce dish offsets separately for x and y positions of antennas - the perturbed array is the same for all runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x + np.load('/home/zahra/corrcal2/random_pt1_x_64.npy')[:Ndish]\n",
    "y = y + np.load('/home/zahra/corrcal2/random_pt1_y_64.npy')[:Ndish]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I get the redundant blocks using a separate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_arr_dish_indices, sum_counts, bl_redundancy_ordered, _, _ = Bls_counts(m)\n",
    "lims = np.append(0, np.cumsum(bl_redundancy_ordered)) #these are the edges of the redundant \n",
    "#blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant1 = bl_arr_dish_indices[:,0].astype(int)\n",
    "ant2 = bl_arr_dish_indices[:,1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Frequency = 400. #MHz\n",
    "Nside = 256\n",
    "zenith = t.zenith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_arr(freq):\n",
    "    '''\n",
    "    Calculates baselines in uv coordinates\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    freq : float\n",
    "        The frequency at which you are observing (in MHz).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    baselines : ndarray\n",
    "        The baselines in uv coordinates (Nbls,2)\n",
    "        Organised according to baseline redundancy\n",
    "    '''\n",
    "    wavelength = (3.e8)/(freq*10.**6)\n",
    "    bl_arr_uv = np.zeros((Nbls,2))\n",
    "    for i in range(len(bl_arr_dish_indices)):\n",
    "        dish_0, dish_1 = bl_arr_dish_indices[i]\n",
    "        bl_ind = [np.int(dish_0), np.int(dish_1)]\n",
    "        u_coord = (x[bl_ind[1]] - x[bl_ind[0]])/wavelength\n",
    "        v_coord = (y[bl_ind[1]] - y[bl_ind[0]])/wavelength\n",
    "        bl_arr_uv[i,:] += np.array([u_coord, v_coord])\n",
    "    return bl_arr_uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gauss_beam(freq, nside): \n",
    "    '''\n",
    "    Calculates the beam model\n",
    "    We assume a Gaussian beam, and assume the same beam for each antenna\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    freq : float\n",
    "        The frequency at which you are observing (in MHz).\n",
    "    nside : int\n",
    "        The dimensions of the HEALPix map used\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Beam : ndarray\n",
    "        Beam model for each pixel (npix,)\n",
    "    '''\n",
    "    wavelength = (3.e8)/(freq*10.**6)    \n",
    "    fwhm = 1.* wavelength/6.\n",
    "    sigma_beam = gaussian_fwhm_to_sigma*fwhm\n",
    "    angpos = hputil.ang_positions(nside)\n",
    "    seps = separations(angpos, zenith)\n",
    "    beam = np.exp(-seps**2/2/sigma_beam**2)\n",
    "    return beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mu function follows the equation $\\mu_n = \\int S^n \\frac{dN}{dS} dS$, with n=2 used for visibilities and n=3 for sky cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mu(index):\n",
    "    '''\n",
    "    Calculates mu by assuming a differential source count, dN/dS, as per Santos et al, 2005\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    index : int\n",
    "        Input the index of source flux, S, depending on what you which to calculate\n",
    "        n = 2 for visibilities due to unresolved point sources following a Poisson distribution\n",
    "        n = 3 for the covariance of the visibilities due to these point sources\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mu_n : float\n",
    "        A constant, computed as per the equation above\n",
    "    '''\n",
    "    S_max =  5 * 12 * 1.e-6 * np.sqrt(1024./Ndish) #12 micro jansky sensitivity for full array,\n",
    "    # scaled for our size array, multiplied by 5 for a 5\\sigma detection\n",
    "    alpha = 4000 \n",
    "    beta = 1.75\n",
    "    mu_index = alpha/(index-beta) * (S_max**(index-beta))\n",
    "    return mu_index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I give details of generating the bright point source map (These are taken from cora - one of the Radio Cosmology packages). The functions below show that fluxes from a flux distribution are placed in random pixels, such that we can treat individual pixels as sources.\n",
    "\n",
    "Please note that the next three cells are taken from cora and are not written by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_min = 2.\n",
    "flux_max = 2.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1 = 1.75\n",
    "gamma2 = 2.51\n",
    "S_0 = 0.88\n",
    "k1 = 1.52e3\n",
    "\n",
    "spectral_mean = -0.7\n",
    "spectral_width = 0.1\n",
    "\n",
    "spectral_pivot = 151.0\n",
    "\n",
    "def source_count(flux):\n",
    "    r\"\"\"Power law luminosity function.\"\"\"\n",
    "\n",
    "    s = flux / S_0\n",
    "\n",
    "    return k1 / (s**gamma1 + s**gamma2)\n",
    "\n",
    "def spectral_realisation(flux, freq):\n",
    "    r\"\"\"Power-law spectral function with Gaussian distributed index.\"\"\"\n",
    "\n",
    "    ind = spectral_mean + spectral_width * np.random.standard_normal(flux.shape)\n",
    "\n",
    "    return flux * (freq / spectral_pivot)**ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population(area):\n",
    "    r\"\"\"Create a set of point sources.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    area : float\n",
    "        The area the population is contained within (in sq degrees).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sources : ndarray\n",
    "        The fluxes of the sources in the population.\n",
    "    \"\"\"\n",
    "\n",
    "    rate = lambda s: flux_min*np.exp(s)*area*source_count(flux_min*np.exp(s))\n",
    "    fluxes = flux_min * np.exp(ps.inhomogeneous_process_approx(np.log(flux_max/flux_min), rate))\n",
    "\n",
    "    return fluxes\n",
    "\n",
    "\n",
    "def getsky(freq, nside):\n",
    "    \"\"\"Simulate a map of point sources.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sky : ndarray [nfreq, npix]\n",
    "        Map of the brightness temperature on the sky (in Jy).\n",
    "    \"\"\"\n",
    "\n",
    "    npix = 12*nside**2\n",
    "\n",
    "    nfreq =1\n",
    "\n",
    "    sky = np.zeros((nfreq, npix), dtype=np.float64)\n",
    "\n",
    "    fluxes = generate_population(4*np.pi)\n",
    "\n",
    "    sr = spectral_realisation(fluxes[:,np.newaxis], freq)\n",
    "\n",
    "    for i in range(sr.shape[0]):\n",
    "        # Pick random pixel\n",
    "        ix = int(np.random.rand() * npix)\n",
    "\n",
    "        sky[:, ix] += sr[i,:]\n",
    "    return sky\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = getsky(Frequency, Nside)[0] # I save this array for each flux range that I consider so \n",
    "#that the source positions are the same for each run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the function to generate the source vector. Ideally, when computing the per visibility response to each source for each baseline, I would consider each pixel in the HEALPix map. This takes about two hours to finish running, and scales up considerably with an increase in the number of bright sources. Thus, I only include the pixels that contribute to the visilities (i.e. include pixels that give non-zero visibilities). As a result, I multiply the map values and beammodel, and consider the pixels for which this product is larger than some value (set to $10^{-3}$ in the function below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Src_vector(freq, nside, map):\n",
    "    '''\n",
    "    Calculates the source vector, S, that is input into CorrCal (for known source positions), \n",
    "    and contains the per visibility response to bright sources with known position. \n",
    "    Vector S is then used to calculate the total visibility contribution from bright sources. \n",
    "    Note that we have separated S into its real and imaginary but have not separated the \n",
    "    visibilities into these components as yet\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    freq : float\n",
    "        The frequency at which you are observing (in MHz).\n",
    "    nside : int\n",
    "        The dimensions of the HEALPix map used\n",
    "    map : ndarray\n",
    "        The map of bright point sources that you are using (npix,)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    source vector : tuple\n",
    "        Vis_bright_sources : Visibilities due to bright point sources (Nbls,)\n",
    "        src_total : Per visibility response to sources with known positions (2*Nsources, 2*Nbls)\n",
    "    '''\n",
    "    fringe = visibility.fringe\n",
    "    angpos = hputil.ang_positions(nside)\n",
    "    beammodel = Gauss_beam(freq, nside)\n",
    "    bl_arr = baseline_arr(freq)\n",
    "    map_vals = map\n",
    "    vals_beam = map_vals*beammodel\n",
    "    pix_valsbeam = np.where(vals_beam >1e-3)[0] #reducing this value from 1e-3 gives bad results\n",
    "    # for the 1-1.2 Jy case with known positions\n",
    "    source_number = len(pix_valsbeam)\n",
    "    src = np.zeros((len(bl_arr_dish_indices), source_number), dtype='complex')\n",
    "    for n in range(source_number):\n",
    "        non_zero_pix = pix_valsbeam[n]\n",
    "        for i in range(len(bl_arr_dish_indices)):\n",
    "            fringe_ind = fringe(angpos[non_zero_pix], zenith, bl_arr[i])\n",
    "            vis_ind_source_ind = map_vals[non_zero_pix] * beammodel[non_zero_pix]**2 * fringe_ind\n",
    "            src[i, n] = vis_ind_source_ind\n",
    "    Vis_bright_sources = np.sum(src, axis=1)\n",
    "    src_total = np.zeros((2*Nbls, 2*source_number))\n",
    "    src_total[::2,::2] = src.real\n",
    "    src_total[1::2,1::2] = src.imag\n",
    "    src_total = src_total.T\n",
    "    return Vis_bright_sources, src_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visibilities due bright sources is then computed by summing over the per visibility response of each bright source, in the source vector, S, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vis_bright_sources, src_total = Src_vector(Frequency, Nside, Map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, to speed up the code, I do not include each pixel of the HEALPix map when generating visibilities of unresolved, dim sources, with a Poisson distribution. I only include pixels where the beam is larger than $10^{-10}$, as demonstrated in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Visibilities_poisson(freq, nside):\n",
    "    '''\n",
    "    Calculates visibilities due to unresolved point sources below the S_{max} set by the \n",
    "    telescope sensitivity. We assume sources follow a Poisson distribution, and do not account \n",
    "    for source clustering. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    freq : float\n",
    "        The frequency at which you are observing (in MHz).\n",
    "    nside : int\n",
    "        The dimensions of the HEALPix map used\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    vis_poisson : ndarray\n",
    "        Visibilities of unresolved sources (Nbls,)\n",
    "    '''\n",
    "    fringe = visibility.fringe\n",
    "    angpos = hputil.ang_positions(nside)\n",
    "    npix = hp.nside2npix(nside)\n",
    "    beammodel = Gauss_beam(freq, nside)\n",
    "    bl_arr = baseline_arr(freq)\n",
    "    point_source_vis = Mu(2)\n",
    "    pix_beam = np.where(beammodel>1e-10)[0]\n",
    "    vis_poisson = np.array([])\n",
    "    for i in range(len(bl_arr_dish_indices)):\n",
    "        fringe_ind = fringe(angpos[pix_beam], zenith, bl_arr[i])\n",
    "        vis_ind = 4 * np.pi/npix * point_source_vis * np.sum(beammodel[pix_beam]**2 * fringe_ind)\n",
    "        vis_poisson = np.append(vis_poisson, vis_ind)\n",
    "    return vis_poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vis_poisson = Visibilities_poisson(Frequency, Nside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vis_total = Vis_poisson + Vis_bright_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The redundant blocking that I use in the function below is the same as that used for the perfectly redundant case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Covariance_poisson(freq, nside):\n",
    "    '''\n",
    "    Covariance matrix computed using unresolved point sources following a Poisson distribution,\n",
    "    and we compute the covariance at a single frequency, across different baselines. \n",
    "    Covariance matrices are computed separately for each redundant block such that we do not \n",
    "    compute a full (Nbls, Nbls) matrix\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    freq : float\n",
    "        The frequency at which you are observing (in MHz).\n",
    "    nside : int\n",
    "        The dimensions of the HEALPix map used\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    vis_poisson : dict\n",
    "        Separate n x n covariance matrices for each redundant block, with the matrix size \n",
    "        depending on the baseline redundancy\n",
    "    '''\n",
    "    angpos = hputil.ang_positions(nside)\n",
    "    npix = hp.nside2npix(nside)\n",
    "    point_source_cov = Mu(3)\n",
    "    bl_arr = baseline_arr(freq)\n",
    "    beammodel = Gauss_beam(freq, nside)\n",
    "    pix_beam = np.where(beammodel>1e-10)[0]\n",
    "\n",
    "    Cov_dic ={} \n",
    "    for ubl_k in range(len(lims)-1):\n",
    "        block_k = bl_redundancy_ordered[ubl_k]\n",
    "        cov_k =np.zeros((block_k,block_k), dtype='complex') \n",
    "        for bl_w in range(block_k):\n",
    "            for bl_z in range(block_k):\n",
    "                u_alph_bet = bl_arr[bl_w] - bl_arr[bl_z]\n",
    "                fringes_ind = visibility.fringe(angpos[pix_beam], zenith, u_alph_bet)\n",
    "                cov_k[bl_w][bl_z] = 4 * np.pi/npix * point_source_cov * np.sum(beammodel[pix_beam]**4*fringes_ind)\n",
    "        Cov_dic[ubl_k]= cov_k\n",
    "    return Cov_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vecs(freq, nside):\n",
    "    '''\n",
    "    Decomposes the covariance matrix into eigenvalues and eigenvectors, separately for each\n",
    "    redundant block. This is the R vector that is input into CorrCal (if you are not using the \n",
    "    redundant case in CorrCal). We set a threshold for the eigenvalues that are considered,\n",
    "    which determines the number of vectors, nvec. Also R is separated into its real and \n",
    "    imaginary components\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    freq : float\n",
    "        The frequency at which you are observing (in MHz).\n",
    "    nside : int\n",
    "        The dimensions of the HEALPix map used\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    vecs : ndarray\n",
    "        R vector (2*Nvec, 2*Nbls)\n",
    "    '''\n",
    "    Cov_dic = Covariance_poisson(freq, nside)\n",
    "    thresh = 1.e-6\n",
    "\n",
    "    ind_array=np.array([])\n",
    "    for i in range(len(lims)-1):\n",
    "        myeig, myvecs = np.linalg.eig(Cov_dic[i])    \n",
    "        ind = np.sum(myeig > thresh * myeig.max()) #Only eigenvalues with 10^{-6} times the max\n",
    "        # eigenvalue are considered\n",
    "        ind_array = np.append(ind_array, ind)\n",
    "\n",
    "    nvec = np.int((ind_array).max())\n",
    "\n",
    "    vecs = np.zeros((2*Nbls,2*nvec))\n",
    "\n",
    "    for i in range(len(lims)-1):\n",
    "        myeig, myvecs = np.linalg.eig(Cov_dic[i])\n",
    "        ind = myeig >thresh * myeig.max() # picking up an index\n",
    "        myeig = myeig[ind] # pick max eigenvalue\n",
    "        myvecs = myvecs[:,ind]\n",
    "\n",
    "        for j in range(len(myeig)): \n",
    "                myvecs[:,j]= myvecs[:,j]*np.sqrt(myeig[j])\n",
    "                vecs[2*lims[i]:2*lims[i+1]:2, 2*j] = np.column_stack(myvecs[:,j].real)\n",
    "                vecs[(2*lims[i]+1):(2*lims[i+1]+1):2, 2*j+1] = np.column_stack(myvecs[:,j].imag)\n",
    "    #Note that every first row and first column contains real components, \n",
    "    #every second row and column contains imaginary components\n",
    "    vecs= vecs.T\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = Vecs(Frequency, Nside)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True gains which we set to 1, so that the real and imaginary components correspond to the\n",
    "amplitude and phase, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain = np.ones(Ndish)\n",
    "sim_gains = np.ones(2*Ndish)\n",
    "sim_gains[::2] = gain.real\n",
    "sim_gains[1::2] = gain.imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_zeros = np.zeros(2*Nbls) # used if the source positions are unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1=np.zeros(2*Nbls)\n",
    "v1[0::2]=1\n",
    "v2=np.zeros(2*Nbls)\n",
    "v2[1::2]=1\n",
    "vecs_redundant = np.vstack([v1,v2])*1.e3 # used for the redundant case in CorrCal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gains(freq, nside, src_array, vecs, visibilities):\n",
    "    '''\n",
    "    Computes the recovered gains for both amplitude and phase. The inputs include the source \n",
    "    vector, S. The two options for the vector depend on whether or not source positions are \n",
    "    known.\n",
    "    The vector, R, constructed from the visibility covariance, and the visibilities. The two \n",
    "    options for the vector depend on whether or not you are using the redundant case.\n",
    "    The visibilities input here are noiseless. Noise is input into the visibilities in this \n",
    "    function, and visibilities are then separated into real and imaginary components. I either \n",
    "    use the sum of unresolved and bright sources, or just the unresolved sources.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    freq : float\n",
    "        The frequency at which you are observing (in MHz).\n",
    "    nside : int\n",
    "        The dimensions of the HEALPix map used\n",
    "    src_array : ndarray\n",
    "        The source vector, S (2*Nsources, 2*Nbls)\n",
    "    vecs : ndarray\n",
    "        The covariance vector, R (2*Nvec, 2*Nbls)\n",
    "    visibilities : ndarray\n",
    "        Noiseless visibilities (Nbls,) \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    recovered gains : ndarray\n",
    "        Recovered gains separated in real (amplitude) and imaginary (phase) components (2*Ndish)\n",
    "    '''\n",
    "    S_max =  5 * 12 * 1.e-6 * np.sqrt(1024./Ndish)\n",
    "    sigma = S_max*0.01\n",
    "    diag = sigma**2*np.ones(2*Nbls)\n",
    "    runs = 500\n",
    "    rand_normal = np.random.normal\n",
    "    random_gain = rand_normal(0,1.e-3, 2*Ndish) #initial guess input into corrcal\n",
    "    gvec = np.array([])\n",
    "    for i in range(len(sim_gains)):\n",
    "        gvec=np.append(gvec,sim_gains[i]+random_gain[i])\n",
    "\n",
    "    get_chisq = corrcal.get_chisq\n",
    "    get_gradient = corrcal.get_gradient\n",
    "    mat = corrcal.Sparse2Level(diag,vecs,src_array,2*lims) \n",
    "\n",
    "    rec_gains = np.zeros((runs,Ndish*2))\n",
    "    for ind_run in range(runs):\n",
    "        print (ind_run)\n",
    "        N_real = rand_normal(0, sigma, Nbls)\n",
    "        N_imag = rand_normal(0, sigma, Nbls)\n",
    "        N_comp = np.array([])\n",
    "        for i in range(len(N_real)):\n",
    "            N_comp = np.append(N_comp,complex(N_real[i],N_imag[i]))\n",
    "        vis = visibilities + N_comp\n",
    "\n",
    "        data = np.zeros(2*vis.size)\n",
    "        data[0::2] = vis.real\n",
    "        data[1::2] = vis.imag\n",
    "        fac=1.;\n",
    "        normfac=1.\n",
    "        results = fmin_cg(get_chisq, gvec*fac, get_gradient,(data,mat,ant1,ant2,fac,normfac))\n",
    "        fit_gains_run = results/fac\n",
    "        rec_gains[ind_run,:] = fit_gains_run\n",
    "        print (fit_gains_run[::2])\n",
    "    return rec_gains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I list the different possibilities I consider:\n",
    "- Recovered gains with bright sources in visibilities and with known positions\n",
    "- Recovered gains with bright sources in visibilities and no known positions\n",
    "- Recovered gains with no bright sources in visibilities (just unresolved, Poisson sources)\n",
    "- Recovered gains with bright sources in visibilities, for the redundant case - no known positions and also no useful information in the R matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_gains = fit_gains(Frequency, Nside, src_total, vecs, Vis_total)\n",
    "#rec_gains = fit_gains(Frequency, Nside, src_zeros, vecs, Vis_total)\n",
    "#rec_gains = fit_gains(Frequency, Nside, src_zeros, vecs, Vis_poisson[1])\n",
    "#rec_gains = fit_gains(Frequency, Nside, src_zeros, vecs_redundant, Vis_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_rel_err_mean_std(rec_gains_amp_or_phase, sim_gains_amp_or_phase):\n",
    "    '''\n",
    "    Histogram of mean and standard deviation of the amplitude/phase relative error\n",
    "    for a number of noise realisations. The error is computed by taking the recovered gains and\n",
    "    subtracting out the true gains.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "   rec_gains_amp_or_phase  : ndarray\n",
    "       The recovered gains for either the amplitude or phase\n",
    "    sim_gains_amp_or_phase : ndarray\n",
    "       The corresponding true gains for either the amplitude or phase\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Standard deviation and mean : tuple\n",
    "        Standard deviation of relative errors (Nruns,)\n",
    "        Mean of relative errors (Nruns,)\n",
    "    '''\n",
    "    rel_error = np.abs(rec_gains_amp_or_phase - sim_gains_amp_or_phase)\n",
    "    rec_gains_mean = np.mean(rel_error, axis=1) #shape is number of runs\n",
    "    rec_gains_std = np.std(rel_error, axis=1, ddof=1)\n",
    "    return rec_gains_std, rec_gains_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std, mean = hist_rel_err_mean_std(rec_gains[:,::2], sim_gains[::2]) # To consider just the \n",
    "#amplitude, we take every second value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mean,'auto') \n",
    "plt.xlabel('Mean')\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(std,'auto') \n",
    "plt.xlabel('Standard deviation')\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
