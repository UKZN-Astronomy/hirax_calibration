{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to run CorrCal with dish scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import h5py,time, matplotlib.pyplot as plt\n",
    "from scipy.optimize import fmin_cg, minimize\n",
    "from drift.core import manager\n",
    "import corrcal\n",
    "import sys\n",
    "sys.path.insert(0,'/home/zahra/PIPELINE')\n",
    "from hirax_transfer import core\n",
    "import scipy as sp\n",
    "from cora.util import hputil\n",
    "from astropy.stats import gaussian_fwhm_to_sigma\n",
    "from hirax_transfer.beams import separations\n",
    "import healpy as hp\n",
    "from cora.core import skysim\n",
    "from cora.foreground import gaussianfg, galaxy\n",
    "from cora.util import coord\n",
    "from drift.core import visibility\n",
    "sys.path.insert(0,'/home/zahra/hirax_tools/')\n",
    "from hirax_tools import array_config\n",
    "from log_red_cal_new import Visibilities_grid, Bls_counts, colour_scatterplot, Scatterplot, index_find\n",
    "from cora.foreground import poisson as ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prod params file used to generate x and y antenna positions, assuming single feed for each antenna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = manager.ProductManager.from_config('/home/zahra/PIPELINE/8by8_no_sims/prod_params_custom.yaml') \n",
    "\n",
    "t = m.telescope\n",
    "Nfeeds,_= t.feedpositions.shape\n",
    "Ndish = np.int(Nfeeds/2)\n",
    "Nbls = np.int(Ndish*(Ndish-1)/2)\n",
    "\n",
    "x = t.feedpositions[:,0][:Ndish] \n",
    "y = t.feedpositions[:,1][:Ndish]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Introduce dish offsets separately for x and y positions of antennas - the perturbed array is the same for all runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x + np.load('/home/zahra/corrcal2/random_pt1_x_64.npy')[:Ndish]\n",
    "y = y + np.load('/home/zahra/corrcal2/random_pt1_y_64.npy')[:Ndish]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I get the redundant blocks using a separate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_arr_dish_indices, sum_counts, bl_redundancy_ordered, _, _ = Bls_counts(m)\n",
    "lims = np.append(0, np.cumsum(bl_redundancy_ordered)) #these are the edges of the redundant blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant1 = bl_arr_dish_indices[:,0].astype(int)\n",
    "ant2 = bl_arr_dish_indices[:,1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Frequency = 400. #MHz\n",
    "Nside = 256\n",
    "zenith = t.zenith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function below returns each baseline in uv coordinates\n",
    "def baseline_arr(freq):\n",
    "    # input freq in MHz\n",
    "    wavelength = (3.e8)/(freq*10.**6)\n",
    "    bl_arr_uv = np.zeros((Nbls,2))\n",
    "    for i in range(len(bl_arr_dish_indices)):\n",
    "        dish_0, dish_1 = bl_arr_dish_indices[i]\n",
    "        bl_ind = [np.int(dish_0), np.int(dish_1)]\n",
    "        u_coord = (x[bl_ind[1]] - x[bl_ind[0]])/wavelength\n",
    "        v_coord = (y[bl_ind[1]] - y[bl_ind[0]])/wavelength\n",
    "        bl_arr_uv[i,:] += np.array([u_coord, v_coord])\n",
    "    return bl_arr_uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The beam - we assume equal Gaussian beams for each antenna\n",
    "def Gauss_beam(freq, nside): \n",
    "    # input freq in MHz\n",
    "    wavelength = (3.e8)/(freq*10.**6)    \n",
    "    fwhm = 1.* wavelength/6.\n",
    "    sigma_beam = gaussian_fwhm_to_sigma*fwhm\n",
    "    angpos = hputil.ang_positions(nside)\n",
    "    seps = separations(angpos, zenith)\n",
    "    beam = np.exp(-seps**2/2/sigma_beam**2)\n",
    "    return beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mu function follows the equation $\\mu_n = \\int S^n \\frac{dN}{dS} dS$, with n=2 used for visibilities and n=3 for sky cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_max =  5 * 12 * 1.e-6 * np.sqrt(1024./Ndish) #12 micro jansky sensitivity for full array,\n",
    "# scaled for our size array, multiplied by 5 for a 5\\sigma detection\n",
    "\n",
    "def Mu(index):\n",
    "    alpha = 4000 \n",
    "    gamma = 0.8\n",
    "    beta = 1.75\n",
    "    mu_index = alpha/(index-beta) * (S_max**(index-beta))\n",
    "    return mu_index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I give details of generating the bright point source map (taken from cora - one of the Radiocosmology packages). The functions below show that fluxes from a flux distribution are placed in random pixels, such that we can individually treat pixels as sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_min = 2.\n",
    "flux_max = 2.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1 = 1.75\n",
    "gamma2 = 2.51\n",
    "S_0 = 0.88\n",
    "k1 = 1.52e3\n",
    "\n",
    "spectral_mean = -0.7\n",
    "spectral_width = 0.1\n",
    "\n",
    "spectral_pivot = 151.0\n",
    "\n",
    "def source_count(flux):\n",
    "    r\"\"\"Power law luminosity function.\"\"\"\n",
    "\n",
    "    s = flux / S_0\n",
    "\n",
    "    return k1 / (s**gamma1 + s**gamma2)\n",
    "\n",
    "def spectral_realisation(flux, freq):\n",
    "    r\"\"\"Power-law spectral function with Gaussian distributed index.\"\"\"\n",
    "\n",
    "    ind = spectral_mean + spectral_width * np.random.standard_normal(flux.shape)\n",
    "\n",
    "    return flux * (freq / spectral_pivot)**ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population(area):\n",
    "    r\"\"\"Create a set of point sources.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    area : float\n",
    "        The area the population is contained within (in sq degrees).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sources : ndarray\n",
    "        The fluxes of the sources in the population.\n",
    "    \"\"\"\n",
    "\n",
    "    rate = lambda s: flux_min*np.exp(s)*area*source_count(flux_min*np.exp(s))\n",
    "    fluxes = flux_min * np.exp(ps.inhomogeneous_process_approx(np.log(flux_max/flux_min), rate))\n",
    "\n",
    "    return fluxes\n",
    "\n",
    "\n",
    "def getsky(freq, nside):\n",
    "    \"\"\"Simulate a map of point sources.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sky : ndarray [nfreq, npix]\n",
    "        Map of the brightness temperature on the sky (in K).\n",
    "    \"\"\"\n",
    "\n",
    "    npix = 12*nside**2\n",
    "\n",
    "    nfreq =1\n",
    "\n",
    "    sky = np.zeros((nfreq, npix), dtype=np.float64)\n",
    "\n",
    "    fluxes = generate_population(4*np.pi)\n",
    "\n",
    "    sr = spectral_realisation(fluxes[:,np.newaxis], freq)\n",
    "\n",
    "    for i in range(sr.shape[0]):\n",
    "        # Pick random pixel\n",
    "        ix = int(np.random.rand() * npix)\n",
    "\n",
    "        sky[:, ix] += sr[i,:]\n",
    "    return sky\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = getsky(Frequency, Nside)[0] # I save this array for each flux range that I consider so \n",
    "#that the source positions are the same for each run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the function to generate the source vector. Ideally, when computing the per visibility response to each source for each baseline, I would consider each pixel in the HEALPix map. This takes about two hours to finish running, and scales up considerably with an increase in the number of bright sources. Thus, I only include the pixels that contribute to the visilities (i.e. include pixels that give non-zero visibilities). As a result, I multiply the map values and beammodel, and consider the pixels for which this product is larger than some value (set to $10^{-3}$ in the function below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Src_vector(freq, nside, map):\n",
    "    fringe = visibility.fringe\n",
    "    angpos = hputil.ang_positions(nside)\n",
    "    beammodel = Gauss_beam(freq, nside)\n",
    "    bl_arr = baseline_arr(freq)\n",
    "    map_vals = map\n",
    "    vals_beam = map_vals*beammodel\n",
    "    pix_valsbeam = np.where(vals_beam >1e-3)[0] #reducing this value from 1e-3 gives bad results\n",
    "    # for the 1-1.2 Jy case with known positions\n",
    "    source_number = len(pix_valsbeam)\n",
    "    src = np.zeros((len(bl_arr_dish_indices), source_number), dtype='complex')\n",
    "    for n in range(source_number):\n",
    "        non_zero_pix = pix_valsbeam[n]\n",
    "        for i in range(len(bl_arr_dish_indices)):\n",
    "            fringe_ind = fringe(angpos[non_zero_pix], zenith, bl_arr[i])\n",
    "            vis_ind_source_ind = map_vals[non_zero_pix] * beammodel[non_zero_pix]**2 * fringe_ind\n",
    "            src[i, n] = vis_ind_source_ind\n",
    "    src_total = np.zeros((2*Nbls, 2*source_number))\n",
    "    src_total[::2,::2] = src.real\n",
    "    src_total[1::2,1::2] = src.imag\n",
    "    src_total = src_total.T\n",
    "    return src, src_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visibilities due bright sources is then computed by summing over the per visibility response of each bright source, in the source vector, S, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_info = Src_vector(Frequency, Nside, Map)\n",
    "src_total = source_info[1] # The source vector, S, shape[N_{source}, N_{baselines}]\n",
    "Vis_bright_sources = np.sum(source_info[0], axis=1) #visibilities due to all bright sources, \n",
    "#shape [N_{baselines}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, to speed up the code, I do not include each pixel of the HEALPix map when generating visibilities of unresolved, dim sources, with a Poisson distribution. I only include pixels where the beam is larger than $10^{-10}$, as demonstrated in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Visibilities_poisson(freq, nside):\n",
    "    fringe = visibility.fringe\n",
    "    angpos = hputil.ang_positions(nside)\n",
    "    npix = hp.nside2npix(nside)\n",
    "    beammodel = Gauss_beam(freq, nside)\n",
    "    bl_arr = baseline_arr(freq)\n",
    "    point_source_vis = Mu(2)\n",
    "    pix_beam = np.where(beammodel>1e-10)[0]\n",
    "    vis_poisson = np.array([])\n",
    "    for i in range(len(bl_arr_dish_indices)):\n",
    "        fringe_ind = fringe(angpos[pix_beam], zenith, bl_arr[i])\n",
    "        vis_ind = 4 * np.pi/npix * point_source_vis * np.sum(beammodel[pix_beam]**2 * fringe_ind)\n",
    "        vis_poisson = np.append(vis_poisson, vis_ind)\n",
    "    return vis_poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vis_poisson = Visibilities_poisson(Frequency, Nside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vis_total = Vis_poisson + Vis_bright_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The redundant blocking that I use in the function below is the same as that used for the perfectly redundant case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Covariance_poisson(freq, nside):\n",
    "    angpos = hputil.ang_positions(nside)\n",
    "    npix = hp.nside2npix(nside)\n",
    "    point_source_cov = Mu(3)\n",
    "    bl_arr = baseline_arr(freq)\n",
    "    beammodel = Gauss_beam(freq, nside)\n",
    "    pix_beam = np.where(beammodel>1e-10)[0]\n",
    "\n",
    "    Cov_dic ={} # dictionary of the sky covariance matrices for all redundant blocks \n",
    "    #at observing frequency\n",
    "    for ubl_k in range(len(lims)-1):\n",
    "        block_k = bl_redundancy_ordered[ubl_k]\n",
    "        cov_k =np.zeros((block_k,block_k), dtype='complex') \n",
    "        for bl_w in range(block_k):\n",
    "            for bl_z in range(block_k):\n",
    "                u_alph_bet = bl_arr[bl_w] - bl_arr[bl_z]\n",
    "                fringes_ind = visibility.fringe(angpos[pix_beam], zenith, u_alph_bet)\n",
    "                cov_k[bl_w][bl_z] = 4 * np.pi/npix * point_source_cov * np.sum(beammodel[pix_beam]**4*fringes_ind)\n",
    "        Cov_dic[ubl_k]= cov_k\n",
    "    return Cov_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vecs(freq, nside):\n",
    "    Cov_dic = Covariance_poisson(freq, nside)\n",
    "    thresh = 1.e-6\n",
    "\n",
    "    ind_array=np.array([])\n",
    "    for i in range(len(lims)-1):\n",
    "        myeig, myvecs = np.linalg.eig(Cov_dic[i])    \n",
    "        ind = np.sum(myeig > thresh * myeig.max()) #Only eigenvalues with 10^{-6} times the max\n",
    "        # eigenvalue are considered\n",
    "        ind_array = np.append(ind_array, ind)\n",
    "\n",
    "    nvec = np.int((ind_array).max())\n",
    "\n",
    "    vecs = np.zeros((2*Nbls,2*nvec))\n",
    "\n",
    "    for i in range(len(lims)-1):\n",
    "        myeig, myvecs = np.linalg.eig(Cov_dic[i])\n",
    "        ind = myeig >thresh * myeig.max() # picking up an index\n",
    "        myeig = myeig[ind] # pick max eigenvalue\n",
    "        myvecs = myvecs[:,ind]\n",
    "\n",
    "        for j in range(len(myeig)): \n",
    "                myvecs[:,j]= myvecs[:,j]*np.sqrt(myeig[j])\n",
    "                vecs[2*lims[i]:2*lims[i+1]:2, 2*j] = np.column_stack(myvecs[:,j].real)\n",
    "                vecs[(2*lims[i]+1):(2*lims[i+1]+1):2, 2*j+1] = np.column_stack(myvecs[:,j].imag)\n",
    "#Note that every first row and first column contains real components, \n",
    "#every second row and column contains imaginary components\n",
    "    vecs= vecs.T\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = Vecs(Frequency, Nside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain = np.ones(Ndish)\n",
    "sim_gains = np.ones(2*Ndish)\n",
    "sim_gains[::2] = gain.real\n",
    "sim_gains[1::2] = gain.imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_zeros = np.zeros(2*Nbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1=np.zeros(2*Nbls)\n",
    "v1[0::2]=1\n",
    "v2=np.zeros(2*Nbls)\n",
    "v2[1::2]=1\n",
    "vecs_redundant = np.vstack([v1,v2])*1.e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gains(freq, nside, src_array, vecs, visibilities):\n",
    "    sigma = S_max*0.01\n",
    "    diag = sigma**2*np.ones(2*Nbls)\n",
    "    runs = 500\n",
    "    rand_normal = np.random.normal\n",
    "    random_gain = rand_normal(0,1.e-3, 2*Ndish) #initial guess input into corrcal\n",
    "    gvec = np.array([])\n",
    "    for i in range(len(sim_gains)):\n",
    "        gvec=np.append(gvec,sim_gains[i]+random_gain[i])\n",
    "\n",
    "    get_chisq = corrcal.get_chisq\n",
    "    get_gradient = corrcal.get_gradient\n",
    "    mat = corrcal.Sparse2Level(diag,vecs,src_array,2*lims) #init\n",
    "\n",
    "    rec_gains = np.zeros((runs,Ndish*2))\n",
    "    for ind_run in range(runs):\n",
    "        print (ind_run)\n",
    "        N_real = rand_normal(0, sigma, Nbls)\n",
    "        N_imag = rand_normal(0, sigma, Nbls)\n",
    "        N_comp = np.array([])\n",
    "        for i in range(len(N_real)):\n",
    "            N_comp = np.append(N_comp,complex(N_real[i],N_imag[i]))\n",
    "        vis = visibilities + N_comp\n",
    "\n",
    "        data = np.zeros(2*vis.size)\n",
    "        data[0::2] = vis.real\n",
    "        data[1::2] = vis.imag\n",
    "        fac=1.;\n",
    "        normfac=1.\n",
    "        results = fmin_cg(get_chisq, gvec*fac, get_gradient,(data,mat,ant1,ant2,fac,normfac))\n",
    "        fit_gains_run = results/fac\n",
    "        rec_gains[ind_run,:] = fit_gains_run\n",
    "        print (fit_gains_run[::2])\n",
    "    return rec_gains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I list the different possibilities I consider:\n",
    "- Recovered gains with bright sources in visibilities and with known positions\n",
    "- Recovered gains with bright sources in visibilities and no known positions\n",
    "- Recovered gains with no bright sources in visibilities (just unresolved, Poisson sources)\n",
    "- Recovered gains with bright sources in visibilities, for the redundant case - no known positions and also no useful information in the R matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_gains = fit_gains(Frequency, Nside, src_total, vecs, Vis_total)\n",
    "#rec_gains = fit_gains(Frequency, Nside, src_zeros, vecs, Vis_total)\n",
    "#rec_gains = fit_gains(Frequency, Nside, src_zeros, vecs, Vis_poisson[1])\n",
    "#rec_gains = fit_gains(Frequency, Nside, src_zeros, vecs_redundant, Vis_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_rel_err_mean_std(rec_gains_amp_or_phase, sim_gains_amp_or_phase):\n",
    "    rel_error = np.abs(rec_gains_amp_or_phase - sim_gains_amp_or_phase)\n",
    "    rec_gains_mean = np.mean(rel_error, axis=1) #shape is number of runs\n",
    "    rec_gains_std = np.std(rel_error, axis=1, ddof=1)\n",
    "    return rec_gains_std, rec_gains_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std, mean = hist_rel_err_mean_std(rec_gains[:,::2], sim_gains[::2]) # To consider just the \n",
    "#amplitude, we take every second value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mean,'auto') \n",
    "plt.xlabel('Mean')\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(std,'auto') \n",
    "plt.xlabel('Standard deviation')\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
